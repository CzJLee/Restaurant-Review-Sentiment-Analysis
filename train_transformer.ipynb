{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdAAAg_J5PxA"
      },
      "source": [
        "# Transformer Model - Positional Embedding and Transformer Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LMGcv9V25PxE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86aQbViP9NjE",
        "outputId": "1a7f693b-e409-4ed4-f4db-8e6208637da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.7.0\n",
            "Mounted at /content/drive\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "Not using a high-RAM runtime\n",
            "Note: Not connected to a TPU runtime.\n"
          ]
        }
      ],
      "source": [
        "# Check if Google Colab Instance for Setup\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "# Get correct path if on Google Colab\n",
        "try:\n",
        "\tfrom google.colab import drive\n",
        "\tdrive.mount(\"/content/drive\")\n",
        "\treviews_dataset_path = \"drive/MyDrive/Colab Notebooks/reviews.json\"\n",
        "\n",
        "\t# Get RAM Info\n",
        "\tfrom psutil import virtual_memory\n",
        "\tram_gb = virtual_memory().total / 1e9\n",
        "\tprint('Your runtime has {:.1f} gigabytes of available RAM'.format(ram_gb))\n",
        "\n",
        "\tif ram_gb < 20:\n",
        "\t\tprint('Not using a high-RAM runtime')\n",
        "\telse:\n",
        "\t\tprint('You are using a high-RAM runtime!')\n",
        "\n",
        "\ttry:\n",
        "\t\ttpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "\t\tprint('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "\n",
        "\t\ttf.config.experimental_connect_to_cluster(tpu)\n",
        "\t\ttf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\t\ttpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "\t\tusing_tpu = True\n",
        "\texcept ValueError:\n",
        "\t\tprint(\"Note: Not connected to a TPU runtime.\")\n",
        "\t\tusing_tpu = False\n",
        "except ModuleNotFoundError:\n",
        "\treviews_dataset_path = \"yelp_dataset/reviews.json\"\n",
        "\tusing_tpu = False\n",
        "\n",
        "AUTO = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NsuxbHGn5PxH"
      },
      "outputs": [],
      "source": [
        "# Read dataset into memory\n",
        "review_df = pd.read_json(reviews_dataset_path, orient=\"records\", lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FuZakueW5PxH"
      },
      "outputs": [],
      "source": [
        "# Shuffle Review df\n",
        "review_df = shuffle(review_df, random_state=0)\n",
        "\n",
        "# Slice into Train, Val, Test at 60:20:20\n",
        "n = len(review_df)\n",
        "df_train = review_df.iloc[: int(n*0.6)]\n",
        "df_val = review_df.iloc[int(n*0.6) : int(n*0.8)]\n",
        "df_test = review_df.iloc[int(n*0.8) :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2VDEKEMh5PxI"
      },
      "outputs": [],
      "source": [
        "# Convert Pandas DF to TF Dataset\n",
        "if using_tpu:\n",
        "\t# TPU's really like big batches I guess. \n",
        "\t# By increasing the batch size by a factor of 128, I am seeing about a 4x speedup. \n",
        "\tbatch_size = 16 * 128 * tpu_strategy.num_replicas_in_sync\n",
        "else:\n",
        "\tbatch_size = 4 * 128\n",
        "\n",
        "def convert_text_df_to_dataset(df, input_col=\"text\", target_col=\"stars\"):\n",
        "\ttext_input = tf.convert_to_tensor(df[input_col], dtype=tf.string)\n",
        "\ttarget = tf.convert_to_tensor(df[target_col], dtype=tf.int8)\n",
        "\tdataset = tf.data.Dataset.from_tensor_slices((text_input, target))\n",
        "\tdataset = dataset.batch(batch_size).prefetch(AUTO)\n",
        "\treturn dataset\n",
        "\n",
        "train_dataset = convert_text_df_to_dataset(df_train)\n",
        "val_dataset = convert_text_df_to_dataset(df_val)\n",
        "test_dataset = convert_text_df_to_dataset(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJMVRzNi9NjH"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RY3vqZUdaGB0"
      },
      "outputs": [],
      "source": [
        "# Transformer Encoder Class\n",
        "class TransformerEncoder(layers.Layer):\n",
        "\tdef __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "\t\tsuper().__init__(**kwargs)\n",
        "\t\tself.embed_dim = embed_dim\n",
        "\t\tself.dense_dim = dense_dim\n",
        "\t\tself.num_heads = num_heads\n",
        "\t\tself.attention = layers.MultiHeadAttention(\n",
        "\t\t\tnum_heads=num_heads, key_dim=embed_dim)\n",
        "\t\tself.dense_proj = keras.Sequential(\n",
        "\t\t\t[layers.Dense(dense_dim, activation=\"relu\"),\n",
        "\t\t\tlayers.Dense(embed_dim),]\n",
        "\t\t)\n",
        "\t\tself.layernorm_1 = layers.LayerNormalization()\n",
        "\t\tself.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "\tdef call(self, inputs, mask=None):\n",
        "\t\tif mask is not None:\n",
        "\t\t\tmask = mask[:, tf.newaxis, :]\n",
        "\t\tattention_output = self.attention(\n",
        "\t\t\tinputs, inputs, attention_mask=mask)\n",
        "\t\tproj_input = self.layernorm_1(inputs + attention_output)\n",
        "\t\tproj_output = self.dense_proj(proj_input)\n",
        "\t\treturn self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\tdef get_config(self):\n",
        "\t\tconfig = super().get_config()\n",
        "\t\tconfig.update({\n",
        "\t\t\t\"embed_dim\": self.embed_dim,\n",
        "\t\t\t\"num_heads\": self.num_heads,\n",
        "\t\t\t\"dense_dim\": self.dense_dim,\n",
        "\t\t})\n",
        "\t\treturn config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T9yCmaqkaGB0"
      },
      "outputs": [],
      "source": [
        "# Positional Embedding Class\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "\tdef __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "\t\tsuper().__init__(**kwargs)\n",
        "\t\tself.token_embeddings = layers.Embedding(\n",
        "\t\t\tinput_dim=input_dim, output_dim=output_dim)\n",
        "\t\tself.position_embeddings = layers.Embedding(\n",
        "\t\t\tinput_dim=sequence_length, output_dim=output_dim)\n",
        "\t\tself.sequence_length = sequence_length\n",
        "\t\tself.input_dim = input_dim\n",
        "\t\tself.output_dim = output_dim\n",
        "\n",
        "\tdef call(self, inputs):\n",
        "\t\tlength = tf.shape(inputs)[-1]\n",
        "\t\tpositions = tf.range(start=0, limit=length, delta=1)\n",
        "\t\tembedded_tokens = self.token_embeddings(inputs)\n",
        "\t\tembedded_positions = self.position_embeddings(positions)\n",
        "\t\treturn embedded_tokens + embedded_positions\n",
        "\n",
        "\tdef compute_mask(self, inputs, mask=None):\n",
        "\t\treturn tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\tdef get_config(self):\n",
        "\t\tconfig = super().get_config()\n",
        "\t\tconfig.update({\n",
        "\t\t\t\"output_dim\": self.output_dim,\n",
        "\t\t\t\"sequence_length\": self.sequence_length,\n",
        "\t\t\t\"input_dim\": self.input_dim,\n",
        "\t\t})\n",
        "\t\treturn config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LRLqLaNb9NjI"
      },
      "outputs": [],
      "source": [
        "# Build Model\n",
        "def create_transformer_model(vocab_size = 20000, sequence_length = 600, embed_dim = 256, num_heads = 2, dense_dim = 32, model_name = None):\n",
        "\tinputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\tx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "\tx = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\tx = layers.GlobalMaxPooling1D()(x)\n",
        "\tx = layers.Dropout(0.5)(x)\n",
        "\toutputs = keras.layers.Dense(1)(x)\n",
        "\n",
        "\tmodel = keras.Model(inputs, outputs, name=model_name)\n",
        "\n",
        "\tmodel.compile(optimizer=\"rmsprop\", loss=\"mean_absolute_error\", metrics=[\"mean_squared_error\"])\n",
        "\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpoDsw8L9NjJ"
      },
      "source": [
        "### Single Word Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1w6XcKnv9NjK"
      },
      "outputs": [],
      "source": [
        "# Create TextVectorization\n",
        "max_tokens = 30000\n",
        "max_length = 500\n",
        "text_vectorization = TextVectorization(max_tokens=max_tokens, output_mode=\"int\", output_sequence_length=max_length)\n",
        "\n",
        "# Train Vectorizer on train text\n",
        "text_vectorization.adapt(df_train[\"text\"])\n",
        "\n",
        "# Vectorize Datasets\n",
        "train_dataset_vectorized = train_dataset.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=AUTO)\n",
        "val_dataset_vectorized = val_dataset.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=AUTO)\n",
        "test_dataset_vectorized = test_dataset.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=AUTO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CurWMIQQ5PxK",
        "outputId": "d916ed9e-5beb-4962-efde-b6e1cdfc89f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " positional_embedding (Posit  (None, None, 256)        7808000   \n",
            " ionalEmbedding)                                                 \n",
            "                                                                 \n",
            " transformer_encoder (Transf  (None, None, 256)        543776    \n",
            " ormerEncoder)                                                   \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,352,033\n",
            "Trainable params: 8,352,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1216/1216 [==============================] - 600s 490ms/step - loss: 0.6633 - mean_squared_error: 0.9895 - val_loss: 0.4406 - val_mean_squared_error: 0.4317\n",
            "Epoch 2/20\n",
            "1216/1216 [==============================] - 596s 490ms/step - loss: 0.4901 - mean_squared_error: 0.5188 - val_loss: 0.4054 - val_mean_squared_error: 0.4812\n",
            "Epoch 3/20\n",
            "1216/1216 [==============================] - 596s 490ms/step - loss: 0.4657 - mean_squared_error: 0.4814 - val_loss: 0.4081 - val_mean_squared_error: 0.4300\n",
            "Epoch 4/20\n",
            "1216/1216 [==============================] - 595s 490ms/step - loss: 0.4492 - mean_squared_error: 0.4584 - val_loss: 0.3717 - val_mean_squared_error: 0.4226\n",
            "Epoch 5/20\n",
            "1216/1216 [==============================] - 595s 490ms/step - loss: 0.4349 - mean_squared_error: 0.4401 - val_loss: 0.4592 - val_mean_squared_error: 0.5102\n",
            "Epoch 6/20\n",
            "1216/1216 [==============================] - 590s 486ms/step - loss: 0.4216 - mean_squared_error: 0.4251 - val_loss: 0.3627 - val_mean_squared_error: 0.4359\n",
            "Epoch 7/20\n",
            "1216/1216 [==============================] - 595s 490ms/step - loss: 0.4107 - mean_squared_error: 0.4120 - val_loss: 0.3948 - val_mean_squared_error: 0.4622\n",
            "Epoch 8/20\n",
            "1216/1216 [==============================] - 595s 490ms/step - loss: 0.4004 - mean_squared_error: 0.3998 - val_loss: 0.3680 - val_mean_squared_error: 0.4572\n",
            "Epoch 9/20\n",
            "1216/1216 [==============================] - 596s 490ms/step - loss: 0.3907 - mean_squared_error: 0.3886 - val_loss: 0.4157 - val_mean_squared_error: 0.4673\n",
            "Epoch 00009: early stopping\n",
            "406/406 [==============================] - 67s 163ms/step - loss: 0.3617 - mean_squared_error: 0.4363\n",
            "Model transformer with MAE 0.362 and MSE 0.436\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_name = \"transformer\"\n",
        "\n",
        "# Creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "if using_tpu:\n",
        "\twith tpu_strategy.scope():\n",
        "\t\tmodel = create_transformer_model(vocab_size = max_tokens, sequence_length = max_length, embed_dim = 256, num_heads = 2, dense_dim = 32, model_name = model_name)\n",
        "else:\n",
        "\tmodel = create_transformer_model(vocab_size = max_tokens, sequence_length = max_length, embed_dim = 256, num_heads = 2, dense_dim = 32, model_name = model_name)\n",
        "\n",
        "# Create callback to save model with a given name\n",
        "model_path = f\"models/{model_name}.keras\"\n",
        "callbacks = [\n",
        "\tkeras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True),\n",
        "\tkeras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5, verbose=1, restore_best_weights=False)\n",
        "]\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train Model\n",
        "model.fit(train_dataset_vectorized, validation_data=val_dataset_vectorized, epochs=20, callbacks=callbacks)\n",
        "\n",
        "# Evaluate Model after training\n",
        "model = keras.models.load_model(model_path, custom_objects={\n",
        "\t\"TransformerEncoder\": TransformerEncoder, \"PositionalEmbedding\": PositionalEmbedding})\n",
        "eval = model.evaluate(test_dataset_vectorized)\n",
        "\n",
        "# Output Model Metrics\n",
        "metrics_text = f\"Model {model_name} with MAE {eval[0]:.3f} and MSE {eval[1]:.3f}\\n\"\n",
        "print(metrics_text)\n",
        "with open(\"model_metrics.txt\", \"a\") as f:\n",
        "\tf.write(metrics_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHSkABXa9NjR"
      },
      "source": [
        "### Categorical Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l-ycaHD89NjS"
      },
      "outputs": [],
      "source": [
        "# Build Model\n",
        "def create_transformer_model_categorical(vocab_size = 20000, sequence_length = 600, embed_dim = 256, num_heads = 2, dense_dim = 32, model_name = None):\n",
        "\tinputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\tx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "\tx = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\tx = layers.GlobalMaxPooling1D()(x)\n",
        "\tx = layers.Dropout(0.5)(x)\n",
        "\toutputs = keras.layers.Dense(6, activation=\"softmax\")(x)\n",
        "\n",
        "\tmodel = keras.Model(inputs, outputs, name=model_name)\n",
        "\n",
        "\tmodel.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FmMnCObF9NjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d18b60b7-96b4-4b3f-9ca1-3d52f61d43cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_categorical\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " positional_embedding_1 (Pos  (None, None, 256)        7808000   \n",
            " itionalEmbedding)                                               \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tran  (None, None, 256)        543776    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,353,318\n",
            "Trainable params: 8,353,318\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1216/1216 [==============================] - 600s 493ms/step - loss: 0.7554 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6337 - val_sparse_categorical_accuracy: 0.7418\n",
            "Epoch 2/20\n",
            "1216/1216 [==============================] - 599s 492ms/step - loss: 0.6246 - sparse_categorical_accuracy: 0.7465 - val_loss: 0.6239 - val_sparse_categorical_accuracy: 0.7457\n",
            "Epoch 3/20\n",
            "1216/1216 [==============================] - 599s 492ms/step - loss: 0.6028 - sparse_categorical_accuracy: 0.7562 - val_loss: 0.6230 - val_sparse_categorical_accuracy: 0.7469\n",
            "Epoch 4/20\n",
            "1216/1216 [==============================] - 599s 492ms/step - loss: 0.5886 - sparse_categorical_accuracy: 0.7623 - val_loss: 0.6216 - val_sparse_categorical_accuracy: 0.7475\n",
            "Epoch 5/20\n",
            "1216/1216 [==============================] - 598s 492ms/step - loss: 0.5763 - sparse_categorical_accuracy: 0.7681 - val_loss: 0.6234 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 6/20\n",
            "1216/1216 [==============================] - 598s 492ms/step - loss: 0.5652 - sparse_categorical_accuracy: 0.7733 - val_loss: 0.6291 - val_sparse_categorical_accuracy: 0.7451\n",
            "Epoch 7/20\n",
            "1216/1216 [==============================] - 598s 492ms/step - loss: 0.5536 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.6385 - val_sparse_categorical_accuracy: 0.7429\n",
            "Epoch 8/20\n",
            "1216/1216 [==============================] - 598s 492ms/step - loss: 0.5414 - sparse_categorical_accuracy: 0.7847 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.7390\n",
            "Epoch 00008: early stopping\n",
            "Model transformer_categorical with MAE 0.315 and MSE 0.508\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_name = \"transformer_categorical\"\n",
        "\n",
        "# Creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "if using_tpu:\n",
        "\twith tpu_strategy.scope():\n",
        "\t\tmodel = create_transformer_model_categorical(vocab_size = max_tokens, sequence_length = max_length, embed_dim = 256, num_heads = 2, dense_dim = 32, model_name = model_name)\n",
        "else:\n",
        "\tmodel = create_transformer_model_categorical(vocab_size = max_tokens, sequence_length = max_length, embed_dim = 256, num_heads = 2, dense_dim = 32, model_name = model_name)\n",
        "\n",
        "# Create callback to save model with a given name\n",
        "model_path = f\"models/{model_name}.keras\"\n",
        "callbacks = [\n",
        "\tkeras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True),\n",
        "\tkeras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5, verbose=1, restore_best_weights=False)\n",
        "]\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train Model\n",
        "model.fit(train_dataset_vectorized, validation_data=val_dataset_vectorized, epochs=20, callbacks=callbacks)\n",
        "\n",
        "# Evaluate Model after training\n",
        "model = keras.models.load_model(model_path, custom_objects={\n",
        "\t\"TransformerEncoder\": TransformerEncoder, \"PositionalEmbedding\": PositionalEmbedding})\n",
        "predictions = model.predict(test_dataset_vectorized)\n",
        "predictions = np.argmax(predictions, axis = -1)\n",
        "true_labels = np.concatenate([y for _, y in test_dataset_vectorized], axis=0)\n",
        "mae = mean_absolute_error(true_labels, predictions)\n",
        "mse = mean_squared_error(true_labels, predictions)\n",
        "\n",
        "\n",
        "# Output Model Metrics\n",
        "metrics_text = f\"Model {model_name} with MAE {mae:.3f} and MSE {mse:.3f}\\n\"\n",
        "print(metrics_text)\n",
        "with open(\"model_metrics.txt\", \"a\") as f:\n",
        "\tf.write(metrics_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mJX5SqEe9NjT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e7c21f1c-6875-4ccf-f1d0-1dcc75d8c9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: models/ (stored 0%)\n",
            "  adding: models/transformer_categorical.keras (deflated 7%)\n",
            "  adding: models/transformer.keras (deflated 7%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a721883a-05aa-4529-8cc3-fb5db910406f\", \"models.zip\", 124584287)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d2f11a53-82ca-4314-af04-5b3db84f1b4b\", \"model_metrics.txt\", 106)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Zip Models\n",
        "!zip -r \"models.zip\" \"models\"\n",
        "\n",
        "try: \n",
        "\tfrom google.colab import files\n",
        "\tfiles.download(\"models.zip\")\n",
        "\tfiles.download(\"model_metrics.txt\")\n",
        "except:\n",
        "\tpass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_transformer.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}