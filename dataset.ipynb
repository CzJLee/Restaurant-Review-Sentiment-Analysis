{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Dataset\n",
    "\n",
    "The Yelp Dataset can be downloaded [here](https://www.yelp.com/dataset). \n",
    "\n",
    "The Yelp Dataset claims to have 8,635,403 reviews. To reduce the scale of this project, I will select a subset of the total dataset. \n",
    "\n",
    "Here is a [useful guide](https://towardsdatascience.com/load-yelp-reviews-or-other-huge-json-files-with-ease-ad804c2f1537) on avoiding reading the entire dataset into memory. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "business_dataset_path = \"yelp_dataset/yelp_academic_dataset_business.json\"\n",
    "review_dataset_path = \"yelp_dataset/yelp_academic_dataset_review.json\"\n",
    "user_dataset_path = \"yelp_dataset/yelp_academic_dataset_user.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select subset based on business location\n",
    "\n",
    "Selecting a subset of reviews for businesses located in California sounds like a good selecting.\n",
    "\n",
    "Or so I thought. It turns out that only certain locations are included in this Yelp Dataset, and California only has 13 businesses included. \n",
    "\n",
    "I guess I could have discovered that earlier by reading the FAQ. \n",
    "\n",
    "> How many and which cities are included in the dataset?\n",
    "> \n",
    "> Currently, the metropolitan areas centered on Montreal, Calgary, Toronto, Pittsburgh, Charlotte, Urbana-Champaign, Phoenix, Las Vegas, Madison, and Cleveland, are included in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Datset has 160585 total entries.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MA     36012\n",
       "OR     25175\n",
       "TX     24485\n",
       "FL     21907\n",
       "GA     18090\n",
       "BC     17298\n",
       "OH     11258\n",
       "CO      3198\n",
       "WA      3121\n",
       "CA        13\n",
       "NH         4\n",
       "AZ         2\n",
       "NY         2\n",
       "VA         2\n",
       "ON         2\n",
       "WY         1\n",
       "OK         1\n",
       "AL         1\n",
       "ME         1\n",
       "NC         1\n",
       "DE         1\n",
       "MI         1\n",
       "ABE        1\n",
       "MN         1\n",
       "KS         1\n",
       "DC         1\n",
       "KY         1\n",
       "IL         1\n",
       "HI         1\n",
       "NM         1\n",
       "WI         1\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Business dataset is relatively small. Let's start by loading that entire dataset into memory, so we can select the businesses located in California. \n",
    "\n",
    "# Read json into memory\n",
    "business_df = pd.read_json(business_dataset_path, orient=\"records\", lines=True)\n",
    "# Keep only features of interest\n",
    "business_columns_to_keep = [\"business_id\", \"state\", \"stars\", \"review_count\", \"is_open\"]\n",
    "business_df = business_df[business_columns_to_keep]\n",
    "\n",
    "print(f\"Business Datset has {len(business_df)} total entries.\")\n",
    "\n",
    "business_df[\"state\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select subset based on review date\n",
    "\n",
    "Since it appears that the dataset only includes businesses in certain locations, perhaps I can select reviews based on the date. \n",
    "\n",
    "Below I read through the entire review dataset to get counts of the number of reviews per year. \n",
    "\n",
    "It seems that the reviews are pretty comprehensive, and the dataset was assembled sometime in early 2021. \n",
    "\n",
    "Now that we know the number of reviews per year, let's select only reviews written in 2019. This selection would be about 1/8 the total dataset. \n",
    "\n",
    "| Year | Number of Reviews |\n",
    "|------|-------------------|\n",
    "| 2004 | 52                |\n",
    "| 2005 | 6439              |\n",
    "| 2006 | 23819             |\n",
    "| 2007 | 71916             |\n",
    "| 2008 | 150436            |\n",
    "| 2009 | 213797            |\n",
    "| 2010 | 317583            |\n",
    "| 2011 | 431192            |\n",
    "| 2012 | 472441            |\n",
    "| 2013 | 555740            |\n",
    "| 2014 | 726119            |\n",
    "| 2015 | 907529            |\n",
    "| 2016 | 960527            |\n",
    "| 2017 | 1029557           |\n",
    "| 2018 | 1084335           |\n",
    "| 2019 | 1037569           |\n",
    "| 2020 | 601891            |\n",
    "| 2021 | 44461             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk 8636 of 8636\n",
      "Merging selected entries into DataFrame...\n",
      "Saving selected reviews to disk...\n",
      "Review subset saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Read through the reviews dataset, selecting only reviews written in 2019\n",
    "\n",
    "# Get counts of the number of reviews written in each year\n",
    "review_years = []\n",
    "review_df = []\n",
    "# Only select reviews with a date in this set of years\n",
    "selected_years = {2019}\n",
    "# Only keep relevent features to reduce the size of our dataset\n",
    "review_columns_to_keep = [\"text\", \"stars\", \"date\"]\n",
    "\n",
    "# Read the JSON object into a JsonReader to iterate chunk by chunk\n",
    "reader = pd.read_json(review_dataset_path, orient=\"records\", lines=True, chunksize=1000)\n",
    "\n",
    "i = 1\n",
    "for chunk in reader:\n",
    "\t# There are about 8,636,000 reviews.\n",
    "\t# With chunksize=1000, there are about 8,636 chunks.\n",
    "\tprint(f\"Reading chunk {i} of 8636\", end=\"\\r\")\n",
    "\ti += 1\n",
    "\n",
    "\t# Extract the year from each review date. \n",
    "\t# This section was used to count the number of reviews per year\n",
    "\tyear = chunk['date'].apply(lambda x: x.year)\n",
    "\treview_years.append(year)\n",
    "\t\n",
    "\t# Keep only reviews where the date has a year in selected_years.\n",
    "\tselected_values = chunk[review_columns_to_keep]\n",
    "\tselected_values = selected_values[selected_values[\"date\"].dt.year.isin(selected_years)]\n",
    "\treview_df.append(selected_values)\n",
    "\n",
    "print(\"\\nMerging selected entries into DataFrame...\")\n",
    "# Make df of selected entries\n",
    "review_years = pd.concat(review_years, ignore_index=True)\n",
    "review_df = pd.concat(review_df, ignore_index=True)\n",
    "\n",
    "# Get count of reviews per year\n",
    "review_years = review_years.value_counts().sort_index()\n",
    "\n",
    "# Drop date from review_df, not needed for NLP\n",
    "review_df.drop(columns=[\"date\"], inplace=True)\n",
    "# Save selected entries to disk\n",
    "print(\"Saving selected reviews to disk...\")\n",
    "review_df.to_json(\"yelp_dataset/reviews.json\", orient=\"records\", lines=True)\n",
    "print(\"Review subset saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004         52\n",
       "2005       6439\n",
       "2006      23819\n",
       "2007      71916\n",
       "2008     150436\n",
       "2009     213797\n",
       "2010     317583\n",
       "2011     431192\n",
       "2012     472441\n",
       "2013     555740\n",
       "2014     726119\n",
       "2015     907529\n",
       "2016     960527\n",
       "2017    1029557\n",
       "2018    1084335\n",
       "2019    1037569\n",
       "2020     601891\n",
       "2021      44461\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display count of reviews per year\n",
    "review_years"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
